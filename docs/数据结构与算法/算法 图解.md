### 数组，字符串

#### 字符串子串与子序列的个数

**假设字符串的长度为 n，那么有 n×(n + 1) / 2 个非空子串**。计算过程如下。

>   长度为 1 的子串，有 n 个
>
>   长度为 2 的子串，每两个每两个相邻地取，一共有 n - 1 个
>
>   长度为 3 的子串，每三个每三个相邻地取，一共有 n - 2 个
>
>   ……
>
>   以此类推，长度为 k 的子串，有 n - k + 1 个。
>
>   当 k 等于 n 的时候，n - k + 1=1，即长度为 n 的子串有 1 个。
>
>   所有情况相加，得到所有子串的长度为：
>
>   n + (n - 1) + (n - 2) + (n - 3) + … + 2 + 1 = n×(n + 1) / 2
>
>   算上空字符串，那么就一共有 n×(n + 1) / 2 + 1 个。

对于一个长度为 n 的字符串，一共有多少个子序列呢？和子串不一样，**子序列里的元素不需要相互挨着**。

>   同理分析，长度为 1 的子序列有 n 个，即 Cn1
>
>   长度为 2 的子序列个数为 Cn2
>
>   以此类推，长度为 k 的子序列有 Cnk
>
>   那么所有子序列的个数（包括空序列）是 Cn0 + Cn1 + Cn2 + … Cnn = 2^n

### 排序

#### 冒泡排序（ Bubble sort）

**基本思想：**给定一个数组，我们把数组里的元素通通倒入到水池中，这些元素将通过相互之间的比较，按照大小顺序一个一个地像气泡一样浮出水面。

**特点：**实现每一轮，从杂乱无章的数组**头部开始**，每两个元素比较大小并进行交换，直到这一轮当中最大或最小的元素被放置在**数组的尾部**，然后不断地重复这个过程，直到所有元素都排好位置。其中，核心操作就是元素相互比较。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/83856600_1569570871.gif)

**算法分析**

**空间复杂度:**假设数组的元素个数是n，由于在整个排序的过程中，我们是直接在给定的数组里面进行元素的两两交换，所以空间复杂度是**O(1)**。

**时间复杂度：**

1.  给定的数组按照顺序已经排好，在这种情况下，我们只需要进行n-1次的比较，两两交换次数为0，时间复杂度是O(n)。这是最好的情况。
2.  给定的数组按照逆序排列，在这种情况下，我们需要进行 n(n-1)/2 次比较，时间复杂度是O(n²)。这是最坏的情况。
3.  给定的数组杂乱无章，在这种情况下，平均时间复杂度是O(n²)。

由此可见，冒泡排序的时间复杂度是**O(n²)**，它是一种稳定的排序算法`（稳定是指如果数组里两个相等的数，那么排序前后这两个相等的数的相对位置保持不变）`。



#### 插入排序（ Insertion sort）

**基本思想：**不断地将尚未排好序的数插入到已经排好序的部分。

**特点：**在冒泡排序中，经过每一轮的排序处理后，数组后端的数是排好序的；而对于插入排序来说，经过每轮的排序处理后，数组前端的数都是排好序的。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/49159600_1569570872.gif)

**算法分析**

**空间复杂度**：假设数组的元素个数是n，由于在整个排序的过程中，是直接在给定的数组里面进行元素的两两交换，空间复杂度是**O(1)**。

**时间复杂度：**

1.  给定的数组按照顺序已经排好，只需要进行n-1次的比较，两两交换次数为0，时间复杂度是O(n)。这是最好的情况。
2.  给定的数组按照逆序排列，在这种情况下，我们需要进行 n(n-1)/2 次比较，时间复杂度是O(n²)。这是最坏的情况。
3.  给定的数组杂乱无章，在这种情况下，平均时间复杂度是O(n²)。

由此可见，和冒泡排序一样，插入排序的时间复杂度是**O(n²)**，并且它也是一种稳定的排序算法。



#### 归并排序（ Merge Sort）

**基本思想：**核心是**分治**，就是把一个复杂的问题分成两个或多个相同或相似的子问题，然后把子问题分成更小的子问题，直到子问题可以简单的直接求解，最原问题的解就是子问题解的合并。归并排序将分治的思想体现得淋漓尽致

**实现：**一开始先把数组从中间划分成两个子数组，一直**递归**地把子数组划分成更小的子数组，直到子数组里面只有**一个**元素，才开始排序。

排序的方法就是按照大小顺序合并两个元素，接着依次按照递归的返回顺序，不断地合并排好序的子数组，直到最后把整个数组的顺序排好。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/6792600_1569570873.gif)

合并过程如下：

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/64472400_1569570873.gif)



**算法分析**

**空间复杂度：**由于合并n个元素需要分配一个大小为n的额外数组，合并完成之后，这个数组的空间就会被释放，所以算法的空间复杂度就是**O(n)**。归并排序也是稳定的排序算法。

**时间复杂度：**归并算法是一个不断递归的过程。整体的复杂度是 **O（n log n）**。

>   举例：数组的元素个数是n，时间复杂度是T (n)的函数。
>
>   解法：把这个规模为n的问题分成两个规模分别为n/2的子问题，每个子问题的时间复杂度就是T（n/2），那么两个子问题的复杂度就是2×T（n/2）。当两个子问题都得到了解决，即两个子数组都排好了序，需要将它们合并，一共有n个元素，每次都要进行最多n-1次的比较，所以合并的复杂度是O（n）。由此我们得到了递归复杂度公式：
>   $$
>   T（n）=2×T（n/2）+O（n）
>   $$
>   对于规模为n的问题，一共要进行log（n）层的大小切分。在每一层里，我们都要进行合并，所涉及到的元素其实就是数组里的所有元素，因此，每一层的合并复杂度都是O（n），所以整体的复杂度就是 O（n log n）



#### 快速排序（ Quick Sort）

**基本思想：**快速排序也采用了**分治**的思想。

**实现：**把原始的数组筛选成较小和较大的两个子数组，然后递归地排序两个子数组。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/24673100_1569570874.gif)

**算法分析**

**空间复杂度：**

和归并排序不同，快速排序在每次递归的过程中，只需要开辟O（1）的存储空间来完成交换操作来完成交换操作实现**直接对数组的修改**，又因为递归次数为log n，所以它的整体空间复杂度完全取决于压堆栈的次数，因此它的空间复杂度是**O（log n）**。

**时间复杂度：**

1.  最优情况：被选出来的基准值都是当前子数组的中间数。

    >   这样的分割，能保证对于一个规模大小为n的问题，能被均匀分解成两个规模大小为n/2的子问题（归并排序也采用了相同的划分方法），时间复杂度就是：
    >   $$
    >   T（n）=2×T（n/2）+O（n）
    >   $$
    >
    >   把规模大小为n的问题分解成n/2的两个子问题时，和基准值进行了n-1次比较，复杂度就是O（n）。很显然，在最优情况下，快速排序的复杂度也是 O（n log n）。

2.  最坏情况：基准值选择了子数组里的**最大**或者**最小**值，每次都把子数组分成了两个更小的子数组，其中一个的**长度为1**，另外一个的长度**只比原子数组少1**。算法复杂度为O（n²）。

平均时间复杂度为**O（n log n）**。



#### 拓扑排序（ Topological Sort）

**基本思想：**和前面介绍的几种排序不同，拓扑排序应用的场合不再是一个简单的数组，而是研究图论里面顶点和顶点连线之间的性质。拓扑排序就是要将这些顶点按照相连的性质进行排序。

要能实现拓扑排序，得有几个前提

1.  图必须是有向图
2.  图里面没有环

>   拓扑排序一般用来理清具有依赖关系的任务。一般来说，一个有向无环图可以有一个或多个拓扑排序的序列。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/75863200_1569570874.gif)

**算法分析**

**时间复杂度：**统计顶点的入度需要O（n）的时间，接下来每个顶点被遍历一次，同样需要O（n）的时间，所以拓扑排序的时间复杂度是**O（n）**。

### 递归与回溯

>   递归和回溯的关系密不可分，递归的基本性质就是函数调用，在处理问题的时候，递归往往是把个大规模的冋题不断地变小然后进行推导的过程。
>
>   回溯则是利用递归的性质，从问题的起始点出发，不断地进行尝试，回头一步甚至多步再做选择，直到最终抵达终点的过程。

#### 递归（ Recursion）

**算法思想：**递归算法是一种调用自身函数的算法（二叉树的许多性质在定义上就满足递归）。将一个问题的规模变小，然后再利用从小规模问题中得出的结果，结合当前的值或者情况，得出最终的结果。

通俗来说，把要实现的递归函数看成是已经实现好的，直接利用解决一些子问题，然后需要考虑的就是如何根据子问题的解以及当前面对的情况得出答案。这种算法也被称为**自顶向下（Top Down）**的算法。

**时间复杂度：**分析递归算法时间复杂度推荐两种方法

-   迭代法

-   公式法

    >   公式法可以说是计算递归函数复杂度最方便的工具，当递归函数的时间执行函数满足如下的关系式时，我们可以利用公式法：
    >   $$
    >   T（n）=a×T（n/b）+f（n）
    >   $$
    >   其中，f（n）是每次递归完毕之后额外的计算执行时间。例如，在归并排序中，每次递归处理完两边的数组后，我们需要执行合并的操作，那么这个操作的执行时间就是f（n）。
    >
    >   当参数a、b都确定的时候，光看递归的部分，它的时间复杂度就是：
    >   $$
    >   O（n^{log_ba}）
    >   $$
    >   由于时间复杂度求的是上界（ upper bound），通过对比递归部分的时间复杂度和f（n）的大小关系，得出最后的整体时间复杂度。牢记以下三种情况和相应公式:
    >
    >   1.  当递归部分的执行时间大于f（n）的时候，最终的时间复杂度就是 O（n^{log_ba}）
    >
    >   2.  当递归部分的执行时间小于f（n）的时候，最终的时间复杂度就是f（n）
    >
    >   3.  当递归部分的执行时间等于f（n）的时候，最终的时间复杂度就是O（n^{log_ba}）* log n

**记忆化（Memoization）**

由于递归的解法需要耗费非常多的重复计算，而且很多计算都是重叠的，避免重叠计算的一种办法就是记忆化。记忆化就是将已经计算出来的结果保存起来，那么下次遇到相同的输入时，直接返回保存好的结果，能够有效节省了大量的计算时间。

**自底向上（Bottom-Up）**

自底向上指，通过状态转移方程，从最小的问题规模入手，不断地增加问题规模，直到所要求的问题规模为止。依然使用记忆化避免重复的计算，不需要递归。



#### 回溯（ Backtracking）

**算法思想:**回溯实际上是一种试探算法，这种算法跟暴力搜索最大的不同在于，在回溯算法里，是一步一步地小心翼翼地进行向前试探，会对每一步探测到的情况进行评估，如果当前的情况已经无法满足要求，那么就没有必要继续进行下去，也就是说，它可以帮助我们避免走很多的弯路。

回溯算法的特点在于，当出现非法的情况时，算法可以回退到之前的情景，可以是返回一步，有时候甚至可以返回多步，然后再去尝试别的路径和办法。这也就意味着，想要采用回溯算法，就必须保证，每次都有多种尝试的可能。

**解题步骤：**

1.  判断当前情况是否非法，如果非法就立即返回；
2.  当前情况是否已经满足递归结束条件，如果是就将当前结果保存起来并返回；
3.  当前情况下，遍历所有可能出现的情况并进行下一步的尝试；
4.  递归完毕后，立即回溯，回溯的方法就是取消前一步进行的尝试。

**时间复杂度：**回溯其实是用递归实现的，因此我们在分析回溯的时间复杂度时，其实就是在对递归函数进行分析，方法和递归一样。

### 动态规划

#### 判断是否为动态规划问题

>   Wikipedia 定义：它既是一种数学优化的方法，同时也是编程的方法

1.  是数学优化的方法——最优子结构

动态规划要解决的都是问题的**最优解**。而一个问题的最优解是由它的各个**子问题的最优解**决定的。由此引出动态规划的第一个重要的属性：**最优子结构(Optimal Substructure)**。一般由最优子结构推导出一个状态转移方程 f(n)，就能很快写出问题的递归实现方法。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/98803400_1569247185.gif) 

2.  是编程的方法——重叠子问题

可以借助编程的技巧去保证**每个重叠的子问题只会被求解一次**。引出了动态规划的第二个重要的属性：**重叠子问题（Overlapping Sub-problems）**。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/33838800_1569247186.gif)    

因此，判断一个问题能不能称得上是动态规划的问题，需要看它是否同时满足这两个重要的属性：最优子结构（Optimal Substructure）和重叠子问题（Overlapping Sub-problems）。

#### 动态规划分类

运用动态规划去解决问题，最难的地方有两个：

1.  应当采用什么样的数据结构来保存什么样的计算结果
2.  如何利用保存下来的计算结果推导出状态转移方程

第一个难点，不仅是为了避免重复的计算，也是推导状态转移方程的关键。这一难点往往是在把问题规模缩小的过程中进行的。

解决技巧：假设已经把所有子问题的最佳结果都计算出来了，那么只需要考虑，如何根据这些子问题的结果来得出最终的答案。

根据动态规划问题的难易程度，把常见的动态规划面试题分成如下三大类：

##### 线性规划

面试题中最常见也是最简单的一种。

线性，就是说各个子问题的规模以线性的方式分布，并且子问题的最佳状态或结果可以存储在一维线性的数据结构里，例如一维数组，哈希表等。

解法中，经常会用 dp[i] 去表示第 i 个位置的结果，或者从 0 开始到第 i 个位置为止的最佳状态或结果。例如，最长上升子序列，dp[i] 表示从数组第 0 个元素开始到第i个元素为止的最长的上升子序列。

求解 dp[i] 的复杂程度取决于题目的要求，但是基本上有两种形式：

>   **求解 dp[i] 形式一**
>
>   第一种形式，当前所求的值仅仅依赖于**有限个**先前计算好的值，也就是说，**dp[i] 仅仅依赖于有限个 dp[j]，其中 j < i**。
>
>   **举例 1**：斐波那契数列。
>
>   解法：dp[i]=dp[i−1] + dp[i−2]，可以看到，当前值只依赖于前面两个计算好的值。
>
>   **求解 dp[i] 形式二**
>
>   第二种求解 dp[i] 的形式，当前所求的值依赖于**所有**先前计算好的值，也就是说，**dp[i] 是各个 dp[j] 的某种组合，其中 j 由 0 遍历到 i−1**。
>
>   **举例 2：**求解最长上升子序列。
>
>   解法：dp[i]=max(dp[j]) + 1，0 <= j < i。可以看到，当前值依赖于前面所有计算好的值。

##### 区间规划

区间规划，就是说各个子问题的规模由不同的区间来定义，一般子问题的最佳状态或结果存储在二维数组里。一般用 dp\[i][j] 代表从第 i 个位置到第 j 个位置之间的最佳状态或结果。

解这类问题的时间复杂度一般为多项式时间，对于一个大小为 n 的问题，时间复杂度不会超过 n 的多项式倍数。例如，O(n)=n^k，k 是一个常数，根据题目的不同而定。

举例：最长回文子序列。

##### 约束规划

在普通的线性规划和区间规划里，一般题目有两种需求：统计和最优解。

这些题目不会对输出结果中的元素有什么限制，只要满足最终的一个条件就好了。但是在很多情况下，题目会对输出结果的元素添加一定的限制或约束条件，增加了解题的难度。

举例：0-1 背包问题。

>   **0-1背包问题** 
>
>   ```
>   c[i][m]=max{c[i-1][m-w[i]]+p[i],c[i-1][m]}
>   ```
>
>   `w[i] :  第i个物体的重量；`
>
>   `p[i] : 第i个物体的价值；`
>
>   `c[i][m] ： 前i个物体放入容量为m的背包的最大价值；`
>
>   `c[i-1][m] ： 前i-1个物体放入容量为m的背包的最大价值；`
>
>   `c[i-1][m-w[i]] ： 前i-1个物体放入容量为m-w[i]的背包的最大价值；`

### 二分搜索（Binary Search）

二分搜索（折半搜索）的 Wikipedia 定义：是一种在有序数组中查找某一特定元素的搜索算法。

从定义可知，运用二分搜索的**前提是数组必须是排好序的**。另外，输入并不一定是数组，也有可能是给定一个区间的起始和终止的位置。

**优点**：时间复杂度是 **O(logn)**，非常高效。因此也称为对数搜索。

**缺点**：要求待查找的数组或者区间是排好序的。

对数组进行动态的删除和插入操作并完成查找，平均复杂度会变为 O(n)。此时应当考虑采取自平衡的**二叉查找树**：

-   在 O(nlogn) 的时间内用给定的数据构建出一棵二叉查找树；
-   在 O(logn) 的时间里对目标数据进行搜索；
-   在 O(logn) 的时间里完成删除和插入的操作。

因此，当输入的数组或者区间是排好序的，同时又不会经常变动，而要求从里面找出一个满足条件的元素的时候，二分搜索就是最好的选择。

二分搜索一般化的解题思路如下。

![img](http://wechatapppro-1252524126.file.myqcloud.com/appcCrwMYBx6232/image/ueditor/43125900_1569237695.gif)    

>   1.  从已经排好序的数组或区间中取出中间位置的元素，判断该元素是否满足要搜索的条件，如果满足，停止搜索，程序结束。
>   2.  如果正中间的元素不满足条件，则从它两边的区域进行搜索。由于数组是排好序的，可以利用排除法，确定接下来应该从这两个区间中的哪一个去搜索。
>   3.  通过判断，如果发现真正要找的元素在左半区间的话，就继续在左半区间里进行二分搜索。反之，就在右半区间里进行二分搜索。

**递归解法：**

优点：简洁；缺点：执行消耗大

```java
int binarySearch(int[] nums, int target, int low, int high) {
        // 为了避免无限循环，先判断，如果起点位置大于终点位置，表明这是一个非法的区间，已经尝试了所有的搜索区间还是没能找到结果，返回 -1。 
if (low > high) {
        return -1;
    }
    // 取正中间那个数的下标 middle。
    int middle = low + (high - low) / 2;
    
    // 判断一下正中间的那个数是不是要找的目标数 target，是，就返回下标 middle。    
    if (nums[middle] == target) {
        return middle;
    }
    
    // 如果发现目标数在左边，就递归地从左半边进行二分搜索。
    if (target < nums[middle]) {
        return binarySearch(nums, target, low, middle - 1);
      } else {
        return binarySearch(nums, target, middle + 1, high);
    }//否则从右半边递归地进行二分搜索。
}
```



>   注意：
>
>   1.  在计算 middle 下标的时候，不能简单地用 (low + hight) / 2，可能会导致溢出。
>   2.  在取左半边以及右半边的区间时，左半边是 [low, middle - 1]，右半边是 [middle + 1, high]，这是两个闭区间。因为已经确定了 middle 那个点不是我们要找的，就没有必要再把它加入到左、右半边了。
>   3.  对于一个长度为奇数的数组，例如：{1, 2, 3, 4, 5}，按照 low + (high - low) / 2 来计算，middle 就是正中间的那个位置，对于一个长度为偶数的数组，例如 {1, 2, 3, 4}，middle 就是正中间靠左边的一个位置。

**时间复杂度**

假设我们要对长度为 n 的数组进行二分搜索，T(n) 是执行时间函数，我们可以得到：
$$
T(n) = T(n/2) + 1
$$
代入公式法得：a = 1，b = 2，f(n) = 1，因此：O(nlog(b)a) = O(n0) = 1 等于 O(f(n))，时间复杂度就是 O(nlog(b)alogn) = **O(logn)**。

**非递归解法：**

```Java
int binarySearch(int[] nums, int target, int low, int high) {
    // 在 while 循环里，判断搜索的区间范围是否有效
    while (low <= high) {
        // 计算正中间的数的下标
        int middle = low + (high - low) / 2;
    
    // 判断正中间的那个数是不是要找的目标数 target。如果是，就返回下标 middle
    if (nums[middle] == target) {
        return middle;
    }
 
  // 如果发现目标数在左边，调整搜索区间的终点为 middle - 1；否则，调整搜索区间的起点为 middle + 1
    if (target < nums[middle]) {
        high = middle - 1;
      } else {
        low = middle + 1;
      }
    }

    // 如果超出了搜索区间，表明无法找到目标数，返回 -1  
    return -1;
}
```

**核心步骤：**

1.  确定搜索的范围和区间
2.  取中间的数判断是否满足条件
3.  如果不满足条件，判定应该往哪个半边继续进行搜索

### 贪婪（Greedy）

贪婪算法的 Wikipedia 定义：是一种在每一步选中都采取在当前状态下最好或最优的选择，从而希望导致结果是最好或最优的算法。

**优点：**

-   对于一些问题，非常直观有效。

**缺点：**

-   并不是所有问题都能用它去解决；
-   得到的结果并一定不是正确的，因为这种算法容易过早地做出决定，从而没有办法达到最优解。